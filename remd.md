## 数据库模型(Database Design) 








## API 接口定义











## 二、三大核心技能梳理
### 1. 大模型微调能力（高薪必备技能）
主流技术路线
  清华智谱智谱系：基于PQ零v二的微调方案；
  主流Laura系：包括Lauraq、Laura adapt等多种Laura变体微调方案。
常用工具：
  底层工具：Deepspeed（偏向底层技术实现，支撑微调的基础架构）；
  应用层工具：llamafactor（更贴近实际应用开发，降低微调技术门槛）。

用llama-factory微调这大一的学学就会吧
千万不要微调，rag性价比高


### 2. Agent开发能力（智能体构建核心）
核心框架：必须基于Longchain、Longgraph框架开发，明确排除“cos和比赛”类非实用开发方向。
关键配套系统：开发的智能体需伴随R&J系统（智能体的知识与逻辑支撑）：
  初级R&J系统：包含向量数据库（实现基础知识检索与存储）；
  高级R&J系统：引入知识图谱（提升智能体的知识关联与深度推理能力，是提升工程师技术价值的关键）。


### 3. 传统主流AI开发技能（工程化基本功）
核心内容：涵盖“小模型开发部署”与“大模型推理部署”两大方向：
  小模型能力：基于papos框架完成小模型的训练与部署（工业界实际应用的基础，是工程师的核心基本功）；
  大模型推理部署：技术门槛较低（类比“运煤”，依赖固定命令），主流工具包括vllm、st浪等，核心不在于工具本身，而在于“小模型与大模型的协同应用”——即如何将Burtt五等小模型合理应用于工业场景。



## 二、17种RAG优化方法详解
### （一）文档切分相关方法（解决“怎么切文档”问题）
#### 1. 简单RAG
核心逻辑：按固定字符或TOKEN数切割文本（如每40字一切）。
示例：文本“苹果公司于2007年发布了第一代iPhone，相比之下，香蕉是一种富含钾的水果”按固定字数切割，可能将“彻底改变了智能”与“手机行业”拆分，导致语义断裂。
优点：实现简单；缺点：切割死板，易造成语义断裂、上下文丢失。

#### 2. 语义切割
核心逻辑：按句子拆分文本，计算相邻句子相似度，相似度骤降处即为切割点，确保每个块语义完整。
示例：上述文本按句子拆分后，因“iPhone”与后续内容相似度下降，最终切成5个语义完整的块。
优点：每个块为完整意思单元，语义连贯；缺点：召回率较低。

#### 3. 上下文分块标题
核心逻辑：分块时为每个块添加对应章节标题，再对“标题+内容”进行嵌入处理。
示例：苹果手机相关内容块添加标题“苹果手机的历史和特性”，香蕉相关内容块添加标题“香蕉的营养和用途”。
优点：避免不同主题块因存在相同词汇而混淆，提升检索精准度。


### （二）检索精准度优化方法（解决“怎么查得准”问题）
#### 4. 上下文增强检索
核心逻辑：检索到相关块后，自动携带其前后相邻的“邻居块”，一并提交给大模型。
示例：用户询问“iPhone有什么特点”，检索到核心相关的块二后，同时携带描述苹果手机历史的块一和描述电池续航的块三。
优点：保留局部上下文，避免信息碎片化。

#### 5. 文本增强
核心逻辑：对每个文本块，通过大模型生成若干对应问题，将“文本块+生成的问题”一同向量化存储，检索时可匹配原文或生成的问题。
示例：针对“第一代iPhone发布”相关块，生成“第一代iPhone什么时候发布的？”“iPhone有物理键盘吗？”等问题，用户提问时可通过问题匹配找到目标块。
优点：大幅提升检索召回率。

#### 6. 查询转换
核心逻辑：通过查询重写、回退提示、子查询分解三种方式，优化用户存在歧义的问题，使其更精准。
示例：用户提问“iphone有没有物理键盘”，重写为“第一代iphone是不是配备了物理键盘”，提升大模型理解度与检索精准度。
优点：减少问题歧义，让检索目标更明确，答案更准确。

#### 7. 重排
核心逻辑：分“粗筛+精筛”两步检索：第一步用语义/相似度检索快速召回20个相关块；第二步用rerank模型逐个打分，仅保留分数最高的Top5块。
示例：检索苹果手机相关信息时，粗筛召回包含苹果、香蕉、机械键盘的3个块，经rerank模型打分后，仅保留相似度9分的苹果相关块。
优点：筛选出最相关的核心信息，提升检索效率与精准度。

#### 8. RSE（关联段落的提取）
核心逻辑：检索到多个相关块后，判断其在原文中是否连续，若连续则拼接成完整段落返回。
示例：检索到块a（苹果手机发布）、块b（苹果手机特性）、块c（苹果手机续航），因三者连续，拼接后整体返回；若块b为香蕉相关内容，则仅返回块a和块c。
优点：提升RAG系统的上下文质量，避免零散信息干扰。

#### 9. 融合RAG
核心逻辑：融合“关键字检索”与“语义检索”两种方式，对两种检索结果打分、加权合并后排序。
优点：结合两种检索的优势，提升检索的准确性与可靠性。

#### 10. Graph RAG
核心逻辑：引入知识图谱，将文档转化为图谱结构，用户提问时通过查找图谱中的相关节点获取信息。
优点：补充文档中的关联关系，让答案更完整、全面。

#### 11. 层次RAG
核心逻辑：先为每个块/每页生成摘要，用户提问时先锁定对应的章节（基于摘要），再在章节内查找细节内容。
类比：类似查字典——先通过拼音/偏旁定位章节，再查询具体汉字细节。
优点：大幅提高查询效率，避免无差别遍历所有文档。

#### 12. Hyde RAG
核心逻辑：“先猜答案再找证据”——用户提问后，先用模型生成假设答案，再以假设答案为检索依据，在知识库中匹配最相似的真实文本块，最终生成响应。
优点：假设答案语义更丰富，与真实文档的匹配度更高，检索更精准。

#### 13. 纠错RAG
核心逻辑：评估检索结果质量，若本地知识库无法满足需求（如实时信息），调用网络检索工具补充。
示例：查询“苹果最新价格”时，本地文档无相关数据，检索质量评估分＜0.3分，自动触发网络检索；若评估分≥0.85分（如查询第一代iPhone发布时间），则直接使用本地文档。
优点：突破本地知识库限制，覆盖实时、稀缺信息，弥补模型知识短板。


### （三）数据使用优化方法（解决“怎么用好数据”问题）
#### 14. 上下文压缩
核心逻辑：对检索到的文本块进行筛选，仅保留与问题相关的句子，删除无关内容。
示例：检索到包含“苹果手机历史+特性”的块，用户询问“苹果手机的特点”时，仅保留“特性”相关内容，剔除“历史”信息。
优点：减少无关信息干扰，让模型回答更精准。

#### 15. 反馈循环
核心逻辑：类似“人类反馈强化学习”，通过用户对响应结果的反馈（如“有用/无用”），调整文档权重或微调嵌入，实现持续优化。
示例：用户对“iPhone是否有物理键盘”的回答点“有用”，下次该用户提问时，对应文本块的检索优先级提升。
优点：让RAG系统“越用越聪明”，贴合用户偏好。

#### 16. 适应性RAG
核心逻辑：先判断问题类型（事实型/分析型/观点型/上下文型），再差异化处理，同时加入多个反思点（是否需要检索、文档是否相关、回答是否有依据等）。
示例：“iPhone有物理键盘吗？”（事实型）→ 检索知识库；“iPhone好用吗？”（观点型）→ 直接生成主观回答。
优点：避免无需检索的问题占用知识库资源，且通过反思点提升回答可靠性。

#### 17. 基于检索的生成
 
#### 18. 基于生成的检索





我需要一个前后端分离的，vue+gin框架的mysql的博客系统

帮我确定我的功能需求和总体架构

以及我的文件夹的目录